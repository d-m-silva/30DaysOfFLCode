{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import gc\n\ngc.collect()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!git clone https://github.com/Xtra-Computing/NIID-Bench\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cd NIID-Bench/\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Removing previous experiment files (if they exist!)**","metadata":{}},{"cell_type":"code","source":"import os\nimport glob\ndir = '/kaggle/working/NIID-Bench/logs'\nfor ext in ['.json', '.log']:\n    files = glob.glob(os.path.join(dir, f'*{ext}'))\n    for file in files:\n        os.remove(file)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!python experiments.py --model=simple-cnn --dataset=cifar10 --alg=fedprox --lr=0.01 --batch-size=64 --rho=0.5 --epochs=5 --n_parties=10 --mu=0.1 --comm_round=5 --partition=noniid-labeldir --beta=0.5 --device='cuda' --datadir='./data/' --logdir='./logs/' --noise=0 --sample=1 --init_seed=0\n!python experiments.py --model=simple-cnn --dataset=cifar10 --alg=fedavg --lr=0.01 --batch-size=64 --rho=0.5 --epochs=5 --n_parties=10 --mu=0.1 --comm_round=5 --partition=noniid-labeldir --beta=0.5 --device='cuda' --datadir='./data/' --logdir='./logs/' --noise=0 --sample=1 --init_seed=0\n!python experiments.py --model=simple-cnn --dataset=cifar10 --alg=scaffold --lr=0.01 --batch-size=64 --rho=0.5 --epochs=5 --n_parties=10 --mu=0.1 --comm_round=5 --partition=noniid-labeldir --beta=0.5 --device='cuda' --datadir='./data/' --logdir='./logs/' --noise=0 --sample=1 --init_seed=0\n!python experiments.py --model=simple-cnn --dataset=cifar10 --alg=fednova --lr=0.01 --batch-size=64 --rho=0.5 --epochs=5 --n_parties=10 --mu=0.1 --comm_round=5 --partition=noniid-labeldir --beta=0.5 --device='cuda' --datadir='./data/' --logdir='./logs/' --noise=0 --sample=1 --init_seed=0     ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import re\n\n\ndef string_to_dict(string):\n    \"\"\"\n    Converts a string representing a Namespace object to a dictionary.\n\n    Args:\n        string: The string to be converted.\n\n    Returns:\n        A dictionary containing the key-value pairs from the Namespace.\n    \"\"\"\n    result = {}\n    pairs = string.split(',')\n    for pair in pairs:\n        key, value = pair.split('=')\n        key = key.strip()\n        value = value.strip().strip(\"'\")\n        result[key] = value\n\n    # Clean keys\n    cleaned_keys = [key[11:].strip('\"') if key.startswith('\"Namespace(') else key.strip('\"') for key in result.keys()]\n\n    # Create a new dictionary with cleaned keys\n    cleaned_result = {cleaned_keys[i]: result[list(result.keys())[i]] for i in range(len(cleaned_keys))}\n\n    return cleaned_result\n\ndef process_experiment(json_file):\n    \"\"\"\n    Processes the arguments json file and respective experiment log \n\n    Args:\n        json_file: path to json file\n\n    Returns:\n        Dictionary with experiment results, or None if there's some issue\n    \"\"\"\n    with open(json_file, 'r') as f:\n        content = f.read()\n        args = string_to_dict(content)\n\n    partition = args.get('partition', None)\n    beta = args.get('beta', None)\n    dataset = args.get('dataset', None)\n    alg = args.get('alg', None)\n    model = args.get('model', None)\n\n    # Extract timestamp from json file\n    timestamp = re.search(r\"experiment_arguments-(\\d{4}-\\d{2}-\\d{2}-\\d{2}:\\d{2}-\\d{2}).json\", json_file).group(1)\n\n    log_file_pattern = f\"logs/experiment_log-{timestamp}.log\"\n    log_files = glob.glob(log_file_pattern)\n    \n\n    if log_files:\n        latest_log = max(log_files, key=lambda x: x.split('-')[2])\n        with open(latest_log, 'r') as file:\n            all_test_accuracies = []\n            for line in file:\n                if \"Test accuracy\" in line and not \"Pre-Training\" in line:\n                    accuracy = float(line.split(\":\")[-1].strip())\n                    all_test_accuracies.append(accuracy)\n            \"\"\"        \n                if \"Global Model Test accuracy\" in line:\n                    last_test_accuracy = line.strip()\n                    last_test_accuracy = float(last_test_accuracy.rsplit(':', 1)[-1].strip())\n                    break\n            \"\"\"        \n    else:\n        print(f\"No log file found for {json_file}\")\n        return None\n\n    if all([partition, beta, dataset, alg, model, all_test_accuracies]): #last_test_accuracy\n        results = {\n            'model': model,\n            'dataset': dataset,\n            'alg': alg,\n            'beta': beta,\n            'partition': partition,\n            'last_test_accuracy': all_test_accuracies #last_test_accuracy\n        }\n        return results\n    else:\n        print(f\"Missing parameters for {json_file}\")\n        return None","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Finding all json files\njson_files = glob.glob('logs/experiment_arguments*')\n\n# Process every json file\nall_results = []\nfor json_file in json_files:\n    result = process_experiment(json_file)\n    if result:\n        all_results.append(result)\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Checking the content of the experiment arguments (json file) and experiment logs (log file)**","metadata":{}},{"cell_type":"code","source":"!cat /logs/experiment_arguments-2024-12-11-14:41-55.json","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!cat logs/experiment_log-2024-12-11-14:41-55.log","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\ndef plot_results(results_dict):\n  \"\"\"\n  Plot with accuracy comparison throghout the epochs, between the four algorithms\n\n  Args:\n    results_dict: dictionaries list, where each dictionary represents an experiment\n  \"\"\"\n\n  for rslt in results_dict:\n    plt.plot(rslt['last_test_accuracy'], label=f\"{rslt['alg']}\")\n\n  plt.xlabel(\"Epoch\")\n  plt.ylabel(\"Test acc\")\n  plt.title(f\"{rslt['partition']} {rslt['model']} on {rslt['dataset']}\")\n  plt.legend()\n  plt.show()\n\nplot_results(all_results)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}