{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "name": "Dist-based_label_imbalance.ipynb",
      "authorship_tag": "ABX9TyMtjNE1Lw05P0nFhnrG0/iK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/d-m-silva/30DaysOfFLCode/blob/main/Dist_based_label_imbalance.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jqf9oDkdBfi6",
        "outputId": "e7da9d47-ac15-4868-e742-e0d178f3f999"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'NIID-Bench'...\n",
            "remote: Enumerating objects: 485, done.\u001b[K\n",
            "remote: Counting objects: 100% (218/218), done.\u001b[K\n",
            "remote: Compressing objects: 100% (75/75), done.\u001b[K\n",
            "remote: Total 485 (delta 198), reused 143 (delta 143), pack-reused 267 (from 1)\u001b[K\n",
            "Receiving objects: 100% (485/485), 1.13 MiB | 21.40 MiB/s, done.\n",
            "Resolving deltas: 100% (288/288), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Xtra-Computing/NIID-Bench"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd NIID-Bench/"
      ],
      "metadata": {
        "id": "RnVHTOSPCGyc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Distribution-based label imbalance**\n",
        "\n",
        "-> Cifar-10, 10 parties, sample rate = 1, batch size = 64, learning rate = 0.01"
      ],
      "metadata": {
        "id": "mUWrcdb0uIfd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python experiments.py --model=simple-cnn --dataset=cifar10 --alg=fedprox --lr=0.01 --batch-size=64 --epochs=5 --n_parties=10 --mu=0.01 --rho=0.9 --comm_round=50 --partition=noniid-labeldir --beta=0.5 --device='cpu' --datadir='./data/' --logdir='./logs/' --noise=0 --sample=1 --init_seed=0\n",
        "!python experiments.py --model=simple-cnn --dataset=cifar10 --alg=fedavg --lr=0.01 --batch-size=64 --epochs=5 --n_parties=10 --mu=0.01 --rho=0.9 --comm_round=50 --partition=noniid-labeldir --beta=0.5 --device='cpu' --datadir='./data/' --logdir='./logs/' --noise=0 --sample=1 --init_seed=0\n",
        "!python experiments.py --model=simple-cnn --dataset=cifar10 --alg=scaffold --lr=0.01 --batch-size=64 --epochs=5 --n_parties=10 --mu=0.01 --rho=0.9 --comm_round=50 --partition=noniid-labeldir --beta=0.5 --device='cpu' --datadir='./data/' --logdir='./logs/' --noise=0 --sample=1 --init_seed=0\n",
        "!python experiments.py --model=simple-cnn --dataset=cifar10 --alg=fednova --lr=0.01 --batch-size=64 --epochs=5 --n_parties=10 --mu=0.01 --rho=0.9 --comm_round=50 --partition=noniid-labeldir --beta=0.5 --device='cpu' --datadir='./data/' --logdir='./logs/' --noise=0 --sample=1 --init_seed=0\n"
      ],
      "metadata": {
        "id": "opjrqGKKBord"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import json\n",
        "import ast\n",
        "\n",
        "\n",
        "def string_to_dict(string):\n",
        "    \"\"\"\n",
        "    Converts a string representing a Namespace object to a dictionary.\n",
        "\n",
        "    Args:\n",
        "        string: The string to be converted.\n",
        "\n",
        "    Returns:\n",
        "        A dictionary containing the key-value pairs from the Namespace.\n",
        "    \"\"\"\n",
        "    result = {}\n",
        "    pairs = string.split(',')\n",
        "    for pair in pairs:\n",
        "        key, value = pair.split('=')\n",
        "        key = key.strip()\n",
        "        value = value.strip().strip(\"'\")\n",
        "        result[key] = value\n",
        "\n",
        "    # Clean keys\n",
        "    cleaned_keys = [key[11:].strip('\"') if key.startswith('\"Namespace(') else key.strip('\"') for key in result.keys()]\n",
        "\n",
        "    # Create a new dictionary with cleaned keys\n",
        "    cleaned_result = {cleaned_keys[i]: result[list(result.keys())[i]] for i in range(len(cleaned_keys))}\n",
        "\n",
        "    return cleaned_result\n",
        "\n",
        "\n",
        "\n",
        "# Find most recent file (json)\n",
        "json_files = glob.glob('logs/experiment_arguments*')\n",
        "if json_files:\n",
        "    latest_json = max(json_files, key=lambda x: x.split('-')[2])  # Order by timestamp\n",
        "\n",
        "    # Open and extract important parameters from json file\n",
        "    with open(latest_json, 'r') as json_file:\n",
        "\n",
        "        content = json_file.read()\n",
        "        args = string_to_dict(content)\n",
        "\n",
        "\n",
        "        # Extract important info\n",
        "        partition = args.get('partition', None)\n",
        "        beta = args.get('beta', None)\n",
        "        dataset = args.get('dataset', None)\n",
        "        alg = args.get('alg', None)\n",
        "        model = args.get('model', None)\n",
        "\n",
        "else:\n",
        "    print(\"No file found\")\n",
        "    partition = beta = dataset = alg = model = None\n",
        "\n",
        "\n",
        "# Find most recent file (log)\n",
        "log_files = glob.glob('logs/experiment_log*')\n",
        "if log_files:\n",
        "    latest_log = max(log_files, key=lambda x: x.split('-')[2])  #Order by timestamp\n",
        "\n",
        "    last_test_accuracy = None\n",
        "\n",
        "    with open(latest_log, 'r') as file:\n",
        "        for line in file:\n",
        "            if \"Global Model Test accuracy\" in line:\n",
        "                last_test_accuracy = line.strip()\n",
        "                last_test_accuracy = float(last_test_accuracy.rsplit(':', 1)[-1].strip())\n",
        "                break  #To guarantee we get only the last ocurrence\n",
        "\n",
        "else:\n",
        "    print(\"No file found.\")\n",
        "    last_test_accuracy = None\n",
        "\n",
        "\n",
        "\n",
        "# Creating dictionary 'results'\n",
        "if all([partition, beta, dataset, alg, model, last_test_accuracy]):\n",
        "    results = {\n",
        "        'model': model,\n",
        "        'dataset': dataset,\n",
        "        'alg': alg,\n",
        "        'beta': beta,\n",
        "        'partition': partition,\n",
        "        'last_test_accuracy': last_test_accuracy\n",
        "    }\n",
        "    print(results)\n",
        "else:\n",
        "    print(\"Parameters missing!\")\n",
        "\n"
      ],
      "metadata": {
        "id": "UWnJvGkiT8tb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}